{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harpy import (\n",
    "    Session,\n",
    "    MapTask,\n",
    "    ReduceTask,\n",
    "    TransformTask,\n",
    "    Result,\n",
    "    TaskSetResults\n",
    ")\n",
    "\n",
    "session = Session().create_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskSet ts-50eb0d8d-f25f-496d-a025-a1bd696dd214: running\n",
      "TaskGroup tg-d4f13a2e-2fbd-4cbe-91bc-29b15e80f8fd made progress\n",
      "TaskGroup tg-d4f13a2e-2fbd-4cbe-91bc-29b15e80f8fd made progress\n",
      "Task tg-d4f13a2e-2fbd-4cbe-91bc-29b15e80f8fd-tr-0: queued\n",
      "TaskGroup tg-d4f13a2e-2fbd-4cbe-91bc-29b15e80f8fd made progress\n",
      "Task tg-d4f13a2e-2fbd-4cbe-91bc-29b15e80f8fd-tr-0: running\n",
      "Task tg-d4f13a2e-2fbd-4cbe-91bc-29b15e80f8fd-tr-0: done\n",
      "Task tg-d4f13a2e-2fbd-4cbe-91bc-29b15e80f8fd-tr-0: fetching\n",
      "TaskGroup tg-d4f13a2e-2fbd-4cbe-91bc-29b15e80f8fd made progress\n",
      "TaskSet ts-50eb0d8d-f25f-496d-a025-a1bd696dd214: compleated\n",
      "Getting results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>filePath</th>\n",
       "      <th>sizeInBytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta</td>\n",
       "      <td>/Volumes/data/delta</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>motor_colisions</td>\n",
       "      <td>/Volumes/data/motor_colisions</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Motor_Vehicle_Collisions_-_Crashes.csv</td>\n",
       "      <td>/Volumes/data/Motor_Vehicle_Collisions_-_Crash...</td>\n",
       "      <td>449301967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>motor_colisions_silver</td>\n",
       "      <td>/Volumes/data/motor_colisions_silver</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flights_1m.parquet</td>\n",
       "      <td>/Volumes/data/Flights_1m.parquet</td>\n",
       "      <td>12942235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 fileName  \\\n",
       "0                                   delta   \n",
       "1                         motor_colisions   \n",
       "2  Motor_Vehicle_Collisions_-_Crashes.csv   \n",
       "3                  motor_colisions_silver   \n",
       "4                      Flights_1m.parquet   \n",
       "\n",
       "                                            filePath  sizeInBytes  \n",
       "0                                /Volumes/data/delta         4096  \n",
       "1                      /Volumes/data/motor_colisions         4096  \n",
       "2  /Volumes/data/Motor_Vehicle_Collisions_-_Crash...    449301967  \n",
       "3               /Volumes/data/motor_colisions_silver         4096  \n",
       "4                   /Volumes/data/Flights_1m.parquet     12942235  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"/Volumes/data/\"\n",
    "#session.fs.ls(\"../_example_data/motor_colisions/\")\n",
    "session.fs.ls(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskSet ts-77ecd600-a01a-4403-9873-0cba47c89130: running\n",
      "TaskGroup tg-695bb162-b240-4e2f-82b4-e64c2c78a843 made progress\n",
      "TaskGroup tg-695bb162-b240-4e2f-82b4-e64c2c78a843 made progress\n",
      "Task tg-695bb162-b240-4e2f-82b4-e64c2c78a843-tr-0: queued\n",
      "TaskGroup tg-695bb162-b240-4e2f-82b4-e64c2c78a843 made progress\n",
      "Task tg-695bb162-b240-4e2f-82b4-e64c2c78a843-tr-0: running\n",
      "Task tg-695bb162-b240-4e2f-82b4-e64c2c78a843-tr-0: done\n",
      "Task tg-695bb162-b240-4e2f-82b4-e64c2c78a843-tr-0: fetching\n",
      "TaskGroup tg-695bb162-b240-4e2f-82b4-e64c2c78a843 made progress\n",
      "TaskSet ts-77ecd600-a01a-4403-9873-0cba47c89130: compleated\n",
      "Getting results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.fs.rm(root + \"motor_colisions_silver\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_sql = f\"\"\"\n",
    "    SELECT \n",
    "        strptime(CONCAT(\"CRASH DATE\", ' - ', \"CRASH TIME\"), '%m/%d/%Y - %H:%M') as crash_datetime,\n",
    "        \"BOROUGH\" as borough,\n",
    "        \"ZIP CODE\" as zip_code,\n",
    "        \"LATITUDE\" as latitude,\n",
    "        \"LONGITUDE\" as longitude,\n",
    "        \"LOCATION\" as location,\n",
    "        \"ON STREET NAME\" as on_street_name,\n",
    "        \"CROSS STREET NAME\" as cross_street_name,\n",
    "        \"OFF STREET NAME\" as off_street_name,\n",
    "        \"NUMBER OF PERSONS INJURED\" as number_of_persons_injured,\n",
    "        \"NUMBER OF PERSONS KILLED\" as number_of_persons_killed,\n",
    "        \"NUMBER OF PEDESTRIANS INJURED\" as number_of_pedestrians_injured,\n",
    "        \"NUMBER OF PEDESTRIANS KILLED\" as number_of_pedestrians_killed,\n",
    "        \"NUMBER OF CYCLIST INJURED\" as number_of_cyclist_injured,\n",
    "        \"NUMBER OF CYCLIST KILLED\" as number_of_cyclist_killed,\n",
    "        \"NUMBER OF MOTORIST INJURED\" as number_of_motorist_injured,\n",
    "        \"NUMBER OF MOTORIST KILLED\" as number_of_motorist_killed,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 1\" as contributing_factor_vehicle_1,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 2\" as contributing_factor_vehicle_2,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 3\" as contributing_factor_vehicle_3,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 4\" as contributing_factor_vehicle_4,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 5\" as contributing_factor_vehicle_5,\n",
    "        \"COLLISION_ID\" as collision_id,\n",
    "        \"VEHICLE TYPE CODE 1\" as vehicle_type_code_1,\n",
    "        \"VEHICLE TYPE CODE 2\" as vehicle_type_code_2,\n",
    "        \"VEHICLE TYPE CODE 3\" as vehicle_type_code_3,\n",
    "        \"VEHICLE TYPE CODE 4\" as vehicle_type_code_4,\n",
    "        \"VEHICLE TYPE CODE 5\" as vehicle_type_code_5\n",
    "    --FROM read_parquet('/Volumes/data/motor_colisions/*.parquet')\n",
    "    FROM read_parquet('{root}motor_colisions/*.parquet')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskSet ts-07aee6d1-6d7e-4c69-8e9a-eac187413a1b: running\n",
      "TaskGroup tg-c690f25c-06c5-4df1-b80b-fbf80c818549 made progress\n",
      "TaskGroup tg-c690f25c-06c5-4df1-b80b-fbf80c818549 made progress\n",
      "Task tg-c690f25c-06c5-4df1-b80b-fbf80c818549-tr-0: queued\n",
      "TaskGroup tg-c690f25c-06c5-4df1-b80b-fbf80c818549 made progress\n",
      "Task tg-c690f25c-06c5-4df1-b80b-fbf80c818549-tr-0: running\n",
      "Task tg-c690f25c-06c5-4df1-b80b-fbf80c818549-tr-0: done\n",
      "Task tg-c690f25c-06c5-4df1-b80b-fbf80c818549-tr-0: fetching\n",
      "TaskGroup tg-c690f25c-06c5-4df1-b80b-fbf80c818549 made progress\n",
      "TaskSet ts-07aee6d1-6d7e-4c69-8e9a-eac187413a1b: compleated\n",
      "Getting results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.fs.mkdir(root + \"motor_colisions_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskSet ts-d73da80b-a60c-4bf4-bc83-cab8fce7c9eb: running\n",
      "TaskGroup tg-12aeb676-35b4-46b8-9667-040893d027bc made progress\n",
      "TaskGroup tg-12aeb676-35b4-46b8-9667-040893d027bc made progress\n",
      "Task tg-12aeb676-35b4-46b8-9667-040893d027bc-tr-0: queued\n",
      "TaskGroup tg-12aeb676-35b4-46b8-9667-040893d027bc made progress\n",
      "Task tg-12aeb676-35b4-46b8-9667-040893d027bc-tr-0: running\n",
      "Task tg-12aeb676-35b4-46b8-9667-040893d027bc-tr-0: done\n",
      "Task tg-12aeb676-35b4-46b8-9667-040893d027bc-tr-0: fetching\n",
      "TaskGroup tg-12aeb676-35b4-46b8-9667-040893d027bc made progress\n",
      "TaskGroup tg-ae31ed10-cb22-4463-bf17-b8f41c838f4d made progress\n",
      "TaskGroup tg-ae31ed10-cb22-4463-bf17-b8f41c838f4d made progress\n",
      "Task tg-ae31ed10-cb22-4463-bf17-b8f41c838f4d-tr-0: queued\n",
      "TaskGroup tg-ae31ed10-cb22-4463-bf17-b8f41c838f4d made progress\n",
      "Task tg-ae31ed10-cb22-4463-bf17-b8f41c838f4d-tr-0: running\n",
      "Task tg-ae31ed10-cb22-4463-bf17-b8f41c838f4d-tr-0: done\n",
      "Task tg-ae31ed10-cb22-4463-bf17-b8f41c838f4d-tr-0: fetching\n",
      "TaskGroup tg-ae31ed10-cb22-4463-bf17-b8f41c838f4d made progress\n",
      "TaskSet ts-d73da80b-a60c-4bf4-bc83-cab8fce7c9eb: compleated\n",
      "Getting results\n"
     ]
    },
    {
     "ename": "TaskSetRuntimeError",
     "evalue": "TaskSetRuntimeError\nTraceback (most recent call last):\n  File \"/opt/remote-runner/_python_base/isolated-session-e3bb842f-b1d5-4025-aba6-986fa33bf9a7/main.py\", line 38, in <module>\n    main()\n  File \"/opt/remote-runner/_python_base/isolated-session-e3bb842f-b1d5-4025-aba6-986fa33bf9a7/main.py\", line 31, in main\n    return_object = unpickled_func(*args, **kwargs)\nTypeError: definition_write_delta_lake() missing 1 required positional argument: 'engine'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTaskSetRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m taskset \u001b[38;5;241m=\u001b[39m taskset_from_sql(silver_sql)\n\u001b[1;32m      4\u001b[0m write_to_deltalake(taskset, root \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmotor_colisions_silver\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtaskset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-quack/harpy/pyharpy/harpy/primitives/__init__.py:20\u001b[0m, in \u001b[0;36mcheck_variable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], variable_name) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], variable_name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_message)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-quack/harpy/pyharpy/harpy/tasksets/__init__.py:213\u001b[0m, in \u001b[0;36mTaskSet.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TaskSetRuntimeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaskSet failed to execute\u001b[39m\u001b[38;5;124m\"\u001b[39m, error_text\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mresults[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstd_err)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [task\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mresults]\n",
      "\u001b[0;31mTaskSetRuntimeError\u001b[0m: TaskSetRuntimeError\nTraceback (most recent call last):\n  File \"/opt/remote-runner/_python_base/isolated-session-e3bb842f-b1d5-4025-aba6-986fa33bf9a7/main.py\", line 38, in <module>\n    main()\n  File \"/opt/remote-runner/_python_base/isolated-session-e3bb842f-b1d5-4025-aba6-986fa33bf9a7/main.py\", line 31, in main\n    return_object = unpickled_func(*args, **kwargs)\nTypeError: definition_write_delta_lake() missing 1 required positional argument: 'engine'\n"
     ]
    }
   ],
   "source": [
    "from harpy.tasksets.tasks import taskset_from_sql, write_to_deltalake\n",
    "\n",
    "taskset = taskset_from_sql(silver_sql)\n",
    "write_to_deltalake(taskset, root + \"motor_colisions_silver\")\n",
    "taskset.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<harpy.session.Session at 0x7fe18dc08a60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deltalake import DeltaTable, write_deltalake\n",
    "from harpy.quack import QuackContext\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Repartition data into N partitions\n",
    "N = 10\n",
    "df_count = session.sql(\"SELECT COUNT(*) as count FROM read_csv('/Volumes/data/Motor_Vehicle_Collisions_-_Crashes.csv')\")\n",
    "total_count = df_count.iloc[0]['count']\n",
    "partition_size = total_count // N\n",
    "remainder = total_count % N\n",
    "\n",
    "def repart_map(location: str, partition_size: int, index: int, remainder: int) -> None:\n",
    "    offset = partition_size * index\n",
    "    limit = partition_size + (1 if index < remainder else 0)\n",
    "    with QuackContext() as q:\n",
    "        q.sql(\"\"\"\n",
    "            COPY (\n",
    "                SELECT * FROM read_csv('{0}', ALL_VARCHAR=True) LIMIT {1} OFFSET {2}\n",
    "            ) TO '/Volumes/data/motor_colisions/file_{3}.parquet' (FORMAT PARQUET, ROW_GROUP_SIZE 1024, COMPRESSION SNAPPY)\n",
    "        \"\"\".format(location, limit, offset, index))\n",
    "\n",
    "ts = session.create_task_set()\n",
    "ts.add_maps([MapTask(\"split\", repart_map, args=[], kwargs={'location': '/Volumes/data/Motor_Vehicle_Collisions_-_Crashes.csv', 'partition_size': partition_size, 'index': i, 'remainder': remainder}) for i in range(N)])\n",
    "\n",
    "results = ts.execute()\n",
    "\n",
    "# Verify the output\n",
    "output_counts = [session.sql(\"SELECT COUNT(*) as count FROM read_parquet('/Volumes/data/motor_colisions/file_{0}.parquet')\".format(i)).iloc[0]['count'] for i in range(N)]\n",
    "total_output_count = sum(output_counts)\n",
    "\n",
    "print(f\"Total input count: {total_count}\")\n",
    "print(f\"Total output count: {total_output_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"SELECT * FROM read_parquet('/Volumes/data/motor_colisions/file_0.parquet')\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"SELECT * FROM read_parquet('/Volumes/data/motor_colisions/file_1.parquet') LIM\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_exp = \"\"\"\n",
    "SELECT \n",
    "    strptime(CONCAT(\"CRASH DATE\", ' - ', \"CRASH TIME\"), '%m/%d/%Y - %H:%M') as crash_datetime,\n",
    "    \"BOROUGH\" as borough,\n",
    "    \"ZIP CODE\" as zip_code,\n",
    "    \"LATITUDE\" as latitude,\n",
    "    \"LONGITUDE\" as longitude,\n",
    "    \"LOCATION\" as location,\n",
    "    \"ON STREET NAME\" as on_street_name,\n",
    "    \"CROSS STREET NAME\" as cross_street_name,\n",
    "    \"OFF STREET NAME\" as off_street_name,\n",
    "    \"NUMBER OF PERSONS INJURED\" as number_of_persons_injured,\n",
    "    \"NUMBER OF PERSONS KILLED\" as number_of_persons_killed,\n",
    "    \"NUMBER OF PEDESTRIANS INJURED\" as number_of_pedestrians_injured,\n",
    "    \"NUMBER OF PEDESTRIANS KILLED\" as number_of_pedestrians_killed,\n",
    "    \"NUMBER OF CYCLIST INJURED\" as number_of_cyclist_injured,\n",
    "    \"NUMBER OF CYCLIST KILLED\" as number_of_cyclist_killed,\n",
    "    \"NUMBER OF MOTORIST INJURED\" as number_of_motorist_injured,\n",
    "    \"NUMBER OF MOTORIST KILLED\" as number_of_motorist_killed,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 1\" as contributing_factor_vehicle_1,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 2\" as contributing_factor_vehicle_2,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 3\" as contributing_factor_vehicle_3,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 4\" as contributing_factor_vehicle_4,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 5\" as contributing_factor_vehicle_5,\n",
    "    \"COLLISION_ID\" as collision_id,\n",
    "    \"VEHICLE TYPE CODE 1\" as vehicle_type_code_1,\n",
    "    \"VEHICLE TYPE CODE 2\" as vehicle_type_code_2,\n",
    "    \"VEHICLE TYPE CODE 3\" as vehicle_type_code_3,\n",
    "    \"VEHICLE TYPE CODE 4\" as vehicle_type_code_4,\n",
    "    \"VEHICLE TYPE CODE 5\" as vehicle_type_code_5\n",
    "FROM read_parquet('../_example_data/motor_colisions/*.parquet')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuackContext exited\n"
     ]
    }
   ],
   "source": [
    "from harpy.quack import QuackContext\n",
    "\n",
    "with QuackContext() as q:\n",
    "    query = q.sql(sql_exp)\n",
    "    arrow_table = query.arrow(rows_per_batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-client-l-33JfS0-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
