{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harpy import (\n",
    "    Session,\n",
    "    MapTask,\n",
    "    ReduceTask,\n",
    "    TransformTask,\n",
    "    Result,\n",
    "    TaskSetResults\n",
    ")\n",
    "\n",
    "session = Session().create_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskSet ts-7bf2fb62-7915-499e-bca5-0c634a7c07c0: running\n",
      "TaskGroup tg-f52b1a9c-6051-4206-93b4-19dc1acbd505 made progress\n",
      "TaskGroup tg-f52b1a9c-6051-4206-93b4-19dc1acbd505 made progress\n",
      "Task tg-f52b1a9c-6051-4206-93b4-19dc1acbd505-tr-0: queued\n",
      "TaskGroup tg-f52b1a9c-6051-4206-93b4-19dc1acbd505 made progress\n",
      "Task tg-f52b1a9c-6051-4206-93b4-19dc1acbd505-tr-0: running\n",
      "Task tg-f52b1a9c-6051-4206-93b4-19dc1acbd505-tr-0: done\n",
      "Task tg-f52b1a9c-6051-4206-93b4-19dc1acbd505-tr-0: fetching\n",
      "TaskGroup tg-f52b1a9c-6051-4206-93b4-19dc1acbd505 made progress\n",
      "TaskSet ts-7bf2fb62-7915-499e-bca5-0c634a7c07c0: compleated\n",
      "Getting results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>filePath</th>\n",
       "      <th>sizeInBytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file_4.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_4.parquet</td>\n",
       "      <td>12671778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file_2.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_2.parquet</td>\n",
       "      <td>12689973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file_6.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_6.parquet</td>\n",
       "      <td>13104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file_3.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_3.parquet</td>\n",
       "      <td>12631968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file_5.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_5.parquet</td>\n",
       "      <td>12647973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>file_8.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_8.parquet</td>\n",
       "      <td>13173939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>file_0.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_0.parquet</td>\n",
       "      <td>12701131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>file_9.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_9.parquet</td>\n",
       "      <td>12460323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>file_1.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_1.parquet</td>\n",
       "      <td>12762999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>file_7.parquet</td>\n",
       "      <td>../_example_data/motor_colisions/file_7.parquet</td>\n",
       "      <td>13098756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fileName                                         filePath  \\\n",
       "0  file_4.parquet  ../_example_data/motor_colisions/file_4.parquet   \n",
       "1  file_2.parquet  ../_example_data/motor_colisions/file_2.parquet   \n",
       "2  file_6.parquet  ../_example_data/motor_colisions/file_6.parquet   \n",
       "3  file_3.parquet  ../_example_data/motor_colisions/file_3.parquet   \n",
       "4  file_5.parquet  ../_example_data/motor_colisions/file_5.parquet   \n",
       "5  file_8.parquet  ../_example_data/motor_colisions/file_8.parquet   \n",
       "6  file_0.parquet  ../_example_data/motor_colisions/file_0.parquet   \n",
       "7  file_9.parquet  ../_example_data/motor_colisions/file_9.parquet   \n",
       "8  file_1.parquet  ../_example_data/motor_colisions/file_1.parquet   \n",
       "9  file_7.parquet  ../_example_data/motor_colisions/file_7.parquet   \n",
       "\n",
       "   sizeInBytes  \n",
       "0     12671778  \n",
       "1     12689973  \n",
       "2     13104800  \n",
       "3     12631968  \n",
       "4     12647973  \n",
       "5     13173939  \n",
       "6     12701131  \n",
       "7     12460323  \n",
       "8     12762999  \n",
       "9     13098756  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.fs.ls(\"../_example_data/motor_colisions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session.fs.ls(\"/Volumes/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_sql = \"\"\"\n",
    "    SELECT \n",
    "        strptime(CONCAT(\"CRASH DATE\", ' - ', \"CRASH TIME\"), '%m/%d/%Y - %H:%M') as crash_datetime,\n",
    "        \"BOROUGH\" as borough,\n",
    "        \"ZIP CODE\" as zip_code,\n",
    "        \"LATITUDE\" as latitude,\n",
    "        \"LONGITUDE\" as longitude,\n",
    "        \"LOCATION\" as location,\n",
    "        \"ON STREET NAME\" as on_street_name,\n",
    "        \"CROSS STREET NAME\" as cross_street_name,\n",
    "        \"OFF STREET NAME\" as off_street_name,\n",
    "        \"NUMBER OF PERSONS INJURED\" as number_of_persons_injured,\n",
    "        \"NUMBER OF PERSONS KILLED\" as number_of_persons_killed,\n",
    "        \"NUMBER OF PEDESTRIANS INJURED\" as number_of_pedestrians_injured,\n",
    "        \"NUMBER OF PEDESTRIANS KILLED\" as number_of_pedestrians_killed,\n",
    "        \"NUMBER OF CYCLIST INJURED\" as number_of_cyclist_injured,\n",
    "        \"NUMBER OF CYCLIST KILLED\" as number_of_cyclist_killed,\n",
    "        \"NUMBER OF MOTORIST INJURED\" as number_of_motorist_injured,\n",
    "        \"NUMBER OF MOTORIST KILLED\" as number_of_motorist_killed,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 1\" as contributing_factor_vehicle_1,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 2\" as contributing_factor_vehicle_2,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 3\" as contributing_factor_vehicle_3,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 4\" as contributing_factor_vehicle_4,\n",
    "        \"CONTRIBUTING FACTOR VEHICLE 5\" as contributing_factor_vehicle_5,\n",
    "        \"COLLISION_ID\" as collision_id,\n",
    "        \"VEHICLE TYPE CODE 1\" as vehicle_type_code_1,\n",
    "        \"VEHICLE TYPE CODE 2\" as vehicle_type_code_2,\n",
    "        \"VEHICLE TYPE CODE 3\" as vehicle_type_code_3,\n",
    "        \"VEHICLE TYPE CODE 4\" as vehicle_type_code_4,\n",
    "        \"VEHICLE TYPE CODE 5\" as vehicle_type_code_5\n",
    "    --FROM read_parquet('/Volumes/data/motor_colisions/*.parquet')\n",
    "    FROM read_parquet('../_example_data/motor_colisions/*.parquet')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskSet ts-59b508cb-4486-425e-b2da-e21b6149fadf: running\n",
      "TaskGroup tg-d3c59194-a462-45e8-bdab-b9ad54a2c970 made progress\n",
      "TaskGroup tg-d3c59194-a462-45e8-bdab-b9ad54a2c970 made progress\n",
      "Task tg-d3c59194-a462-45e8-bdab-b9ad54a2c970-tr-0: queued\n",
      "TaskGroup tg-d3c59194-a462-45e8-bdab-b9ad54a2c970 made progress\n",
      "Task tg-d3c59194-a462-45e8-bdab-b9ad54a2c970-tr-0: running\n",
      "Task tg-d3c59194-a462-45e8-bdab-b9ad54a2c970-tr-0: done\n",
      "Task tg-d3c59194-a462-45e8-bdab-b9ad54a2c970-tr-0: fetching\n",
      "TaskGroup tg-d3c59194-a462-45e8-bdab-b9ad54a2c970 made progress\n",
      "TaskGroup tg-cc3516c7-0bcd-4f2e-b5ca-230ab78e8248 made progress\n",
      "TaskGroup tg-cc3516c7-0bcd-4f2e-b5ca-230ab78e8248 made progress\n",
      "Task tg-cc3516c7-0bcd-4f2e-b5ca-230ab78e8248-tr-0: queued\n",
      "TaskGroup tg-cc3516c7-0bcd-4f2e-b5ca-230ab78e8248 made progress\n",
      "Task tg-cc3516c7-0bcd-4f2e-b5ca-230ab78e8248-tr-0: running\n"
     ]
    }
   ],
   "source": [
    "# Delta tables \n",
    "from deltalake import write_deltalake, DeltaTable\n",
    "import pyarrow as pa\n",
    "from harpy.quack import QuackContext\n",
    "\n",
    "def fetch_arrow_sql(sql:str) -> pa.Table:\n",
    "    with QuackContext() as ctx:\n",
    "        q = ctx.sql(sql)\n",
    "        return q.arrow()\n",
    "    \n",
    "\n",
    "def write_deltalake_from_pa(df:pa.Table, path: str, mode:str) -> None:\n",
    "    write_deltalake(path, df, mode=mode)\n",
    "\n",
    "ts = session.create_task_set()\n",
    "ts.add_maps([MapTask(name=\"fetch-pa-table\", fun=fetch_arrow_sql, args=[], kwargs={'sql': silver_sql})])\n",
    "ts.add_transform(TransformTask(name=\"write-pa-table\", fun=write_deltalake_from_pa, args=[], kwargs={'path': '../_example_data/motor_colisions_silver/', 'mode': 'overwrite'}))\n",
    "\n",
    "result = ts.execute()\n",
    "if result.success == False:\n",
    "    print(result.results[0].std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deltalake import DeltaTable, write_deltalake\n",
    "from harpy.quack import QuackContext\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Repartition data into N partitions\n",
    "N = 10\n",
    "df_count = session.sql(\"SELECT COUNT(*) as count FROM read_csv('/Volumes/data/Motor_Vehicle_Collisions_-_Crashes.csv')\")\n",
    "total_count = df_count.iloc[0]['count']\n",
    "partition_size = total_count // N\n",
    "remainder = total_count % N\n",
    "\n",
    "def repart_map(location: str, partition_size: int, index: int, remainder: int) -> None:\n",
    "    offset = partition_size * index\n",
    "    limit = partition_size + (1 if index < remainder else 0)\n",
    "    with QuackContext() as q:\n",
    "        q.sql(\"\"\"\n",
    "            COPY (\n",
    "                SELECT * FROM read_csv('{0}', ALL_VARCHAR=True) LIMIT {1} OFFSET {2}\n",
    "            ) TO '/Volumes/data/motor_colisions/file_{3}.parquet' (FORMAT PARQUET, ROW_GROUP_SIZE 1024, COMPRESSION SNAPPY)\n",
    "        \"\"\".format(location, limit, offset, index))\n",
    "\n",
    "ts = session.create_task_set()\n",
    "ts.add_maps([MapTask(\"split\", repart_map, args=[], kwargs={'location': '/Volumes/data/Motor_Vehicle_Collisions_-_Crashes.csv', 'partition_size': partition_size, 'index': i, 'remainder': remainder}) for i in range(N)])\n",
    "\n",
    "results = ts.execute()\n",
    "\n",
    "# Verify the output\n",
    "output_counts = [session.sql(\"SELECT COUNT(*) as count FROM read_parquet('/Volumes/data/motor_colisions/file_{0}.parquet')\".format(i)).iloc[0]['count'] for i in range(N)]\n",
    "total_output_count = sum(output_counts)\n",
    "\n",
    "print(f\"Total input count: {total_count}\")\n",
    "print(f\"Total output count: {total_output_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"SELECT * FROM read_parquet('/Volumes/data/motor_colisions/file_0.parquet')\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"SELECT * FROM read_parquet('/Volumes/data/motor_colisions/file_1.parquet') LIM\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_exp = \"\"\"\n",
    "SELECT \n",
    "    strptime(CONCAT(\"CRASH DATE\", ' - ', \"CRASH TIME\"), '%m/%d/%Y - %H:%M') as crash_datetime,\n",
    "    \"BOROUGH\" as borough,\n",
    "    \"ZIP CODE\" as zip_code,\n",
    "    \"LATITUDE\" as latitude,\n",
    "    \"LONGITUDE\" as longitude,\n",
    "    \"LOCATION\" as location,\n",
    "    \"ON STREET NAME\" as on_street_name,\n",
    "    \"CROSS STREET NAME\" as cross_street_name,\n",
    "    \"OFF STREET NAME\" as off_street_name,\n",
    "    \"NUMBER OF PERSONS INJURED\" as number_of_persons_injured,\n",
    "    \"NUMBER OF PERSONS KILLED\" as number_of_persons_killed,\n",
    "    \"NUMBER OF PEDESTRIANS INJURED\" as number_of_pedestrians_injured,\n",
    "    \"NUMBER OF PEDESTRIANS KILLED\" as number_of_pedestrians_killed,\n",
    "    \"NUMBER OF CYCLIST INJURED\" as number_of_cyclist_injured,\n",
    "    \"NUMBER OF CYCLIST KILLED\" as number_of_cyclist_killed,\n",
    "    \"NUMBER OF MOTORIST INJURED\" as number_of_motorist_injured,\n",
    "    \"NUMBER OF MOTORIST KILLED\" as number_of_motorist_killed,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 1\" as contributing_factor_vehicle_1,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 2\" as contributing_factor_vehicle_2,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 3\" as contributing_factor_vehicle_3,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 4\" as contributing_factor_vehicle_4,\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 5\" as contributing_factor_vehicle_5,\n",
    "    \"COLLISION_ID\" as collision_id,\n",
    "    \"VEHICLE TYPE CODE 1\" as vehicle_type_code_1,\n",
    "    \"VEHICLE TYPE CODE 2\" as vehicle_type_code_2,\n",
    "    \"VEHICLE TYPE CODE 3\" as vehicle_type_code_3,\n",
    "    \"VEHICLE TYPE CODE 4\" as vehicle_type_code_4,\n",
    "    \"VEHICLE TYPE CODE 5\" as vehicle_type_code_5\n",
    "FROM read_parquet('../_example_data/motor_colisions/*.parquet')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harpy.quack import QuackContext\n",
    "\n",
    "with QuackContext() as q:\n",
    "    query = q.sql(sql_exp)\n",
    "    arrow_table = query.arrow(rows_per_batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arrow_table.to_batches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-client-l-33JfS0-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
